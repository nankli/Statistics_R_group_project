---
title: "MP_data_processing_model"
author: "Matt Pitz, Nan Li, Ada Guan"
date: '2022-04-03'
output: html_document
---

```{r load packages and set options, include=FALSE}
library(tidyverse) 
library(magrittr)
library(knitr)
if (!require("patchwork")) install.packages('patchwork')
if (!require("moments")) install.packages('moments')
if (!require("arrow")) install.packages('arrow')
library(patchwork)
library(moments)
library(arrow)
library(readr)
library(ggplot2)
library(stargazer)
library(lmtest)
#tinytex::install_tinytex()
theme_set(theme_bw())

options(tinytex.verbose = TRUE)
knitr::opts_chunk$set(echo=FALSE, message=FALSE)

notebooks_path <- getwd()
root_path <- dirname(notebooks_path)
data_path <- file.path(root_path,"src","data","raw")
```

```{r remove pre-2000 data, include=FALSE}
# #only run this snippet once
# 
#  raw_file_path <- file.path(data_path,"movie_data_1950_2020.csv")
# 
#  raw_data <- read.csv(raw_file_path, header = TRUE, sep = ",")
# 
#  #convert release_year to numeric and drop all obs after 200-
#  post_2000_raw <- raw_data %>%
#    mutate(release_year = strtoi(release_year)) %>%
#             filter(release_year >= 2000)
# 
#  #save as parquet file
#  write_parquet(post_2000_raw,
#                sink = file.path(data_path, "post_2000_data"))
# 
# #browse_data <- post_2000_raw[1:50,]
```


```{r load parquet file, include=FALSE}
post_2000_raw <- read_parquet(file = file.path(data_path, "post_2000_data"))

```

```{r inital data cleaning , include=FALSE}
#count total obs (3356 obs)
ttl_count <- nrow(post_2000_raw)

#count obs without missing budget and box office that will be used in analysis
#597 obs >=2000
analysis_count <- post_2000_raw %>%
  filter(box_office != "" & budget != "") %>%
  nrow

#create clean budget and box office numbers
post_2000_raw <- post_2000_raw %>%
  mutate(
    clean_budget = ifelse(
      grepl("m", budget, fixed=TRUE),
      parse_number(budget),
      parse_number(budget)/1000000
      ),
    clean_box_office = ifelse (
      grepl("m", box_office, fixed=TRUE),
      parse_number(box_office),
      parse_number(box_office)/1000000
    )
  )

#correct for billions
post_2000_raw <- post_2000_raw %>%
  mutate(
    clean_box_office = ifelse(
      grepl("b", box_office, fixed=TRUE),
      parse_number(box_office)*1000,
      clean_box_office) 
  )
    

#create primary genre
post_2000_raw$genre_primary <- str_extract(post_2000_raw$genre, "[^/]+")

#combine related categories
post_2000_raw <- post_2000_raw %>%
  mutate(genre_primary = ifelse(
    genre_primary == "Adaptation" | genre_primary == "Docudrama" | genre_primary == "Hip hop" |
    genre_primary == "Historical drama" | genre_primary == "History" | genre_primary == "LGBT" |
    genre_primary == "Pornographic" | genre_primary == "Road",
    "Misc",
    genre_primary
    ),
    genre_primary = ifelse( 
     genre_primary == "Teen",
     "Family",
     genre_primary
    ),
    genre_primary = ifelse( 
     genre_primary == "Psychological thriller",
     "Thriller",
     genre_primary
    ),
    genre_primary = ifelse( 
     genre_primary == "Music",
     "Musical",
     genre_primary
    ),
    genre_primary = ifelse( 
     genre_primary == "Noir",
     "Crime",
     genre_primary
    ),
    genre_primary = ifelse( 
     genre_primary == "Action Thriller",
     "Action",
     genre_primary
    )
  )

#create release month
post_2000_raw$release_month <- str_extract(post_2000_raw$release_date,"(\\w+)") 
post_2000_raw <- post_2000_raw %>% 
  mutate(
    summer = ifelse(
    release_month == "May" |release_month == "June" | release_month == "July", 1,0) 
  )
post_2000_raw <- post_2000_raw %>% 
  mutate(
    thanksxmas = ifelse(
    release_month == "November" |release_month == "December" | release_month == "January",1,0)
  )

#convert duration into minutes
post_2000_raw <- post_2000_raw %>% 
  mutate(
    temp_hours = as.numeric(substr(duration,1,1))*60,
    temp_minutes = ifelse(
      grepl("m",duration),
      parse_number(str_extract(duration, "[0-9]{1,2}m")),
      0),
    duration_minutes = temp_hours + temp_minutes
  ) 

post_2000_raw <- post_2000_raw %>%
  select(-temp_hours, -temp_minutes)

#award flag 
post_2000_raw <- post_2000_raw %>% 
  mutate(
    #received_award = !is.na(awards) 
    received_award = case_when(
    awards == "" ~ 0, 
    awards != "" ~ 1)
  )
post_2000_raw$rotten_tomatoes_rating <- as.numeric(sub("%", "",post_2000_raw$rotten_tomatoes_rating,fixed=TRUE))/100
# post_2000_raw$rotten_tomatoes_rating
```

```{r read in inflation}

#load in inflation
inflation_file_path <- file.path(data_path,"Inflation_Rates.csv")
 
inflation_data <- read.csv(inflation_file_path, header = TRUE, sep = ",")

colnames(inflation_data)[1] <- "release_year"

post_2000_merge <- merge(post_2000_raw,inflation_data ,by="release_year")

#convert dollar values to real
post_2000_merge$clean_budget_real <- post_2000_merge$clean_budget*post_2000_merge$Inflation_Rate
post_2000_merge$clean_box_office_real <- post_2000_merge$clean_box_office*post_2000_merge$Inflation_Rate

# browse_data2 <- post_2000_merge[1000:1030,]
```

```{r, scatter plot}
post_2000_raw_histogram <- post_2000_merge %>%
filter(box_office != "" & budget != "") %>%
  ggplot() + 
  aes(x = clean_budget_real, y = clean_box_office_real, color = genre_primary) +
  geom_point() +
    labs(title ='Box Office Earning Based On Budget',
       x ='Budget (Million $)',
       y ='Box Office (Million $)')

post_2000_raw_histogram
```

###models

Model 1: Baseline model (only including one dependent variable):

$$
\text{log(Box office)} = \beta_0 + \beta_1*\text{log(Budget)}
$$

Model 2: Model including dependent variables of interest:
$$
\text{log(Box office)} = \beta_0 + \beta_1*\text{log(Budget)} + \beta_2*\text{duration} + \beta_3*\text{rotten_tomatoes_rating} + \beta_4*\text{summer} + \beta_5*\text{thanksxmas} + \beta_6*\text{award} + \beta_7*\text{maturity_rating}
$$
'title','maturity_rating','duration_minutes',
                                   'clean_box_office_real','clean_budget_real',
                                   'genre_primary','rotten_tomatoes_rating',
         'release_year','release_month','summer','thanksxmas','received_award')]

Model 3: Model including more dependent variables of interest:
$$
\text{log(Box office)} = \beta_0 + \beta_1*\text{log(Budget)} + \beta_2*\text{duration} + \beta_3*\text{rotten_tomatoes_rating} + \beta_4*\text{summer} + \beta_5*\text{thanksxmas} + \beta_6*\text{award} + \beta_7*\text{maturity_rating} + \beta_8*\text{genre_primary}
$$
```{r select columns of interests}
post_2000_raw <- post_2000_merge[c('title','maturity_rating','duration_minutes',
                                   'clean_box_office_real','clean_budget_real',
                                   'genre_primary','rotten_tomatoes_rating',
         'release_year','release_month','summer','thanksxmas','received_award')]
post_2000 <- na.omit(post_2000_raw)

post_2000 <- post_2000 %>% 
  mutate(
    box_office_log = log(clean_box_office_real + 1), 
    budget_log = log(clean_budget_real + 1)
  )
```
```{r, echo=FALSE, warning=FALSE, message=FALSE, comment=NA}
if (!require("stargazer")) install.packages('stargazer')
if (!require("sandwich")) install.packages('sandwich')
source('./get_robust_se.R')
model_1 = lm(data=post_2000, box_office_log ~ budget_log)
model_2 = lm(data=post_2000, box_office_log ~ budget_log + duration_minutes +
             rotten_tomatoes_rating + summer + thanksxmas + received_award +
               maturity_rating)
model_3 = lm(data=post_2000, box_office_log ~ budget_log + duration_minutes +
             rotten_tomatoes_rating + summer + thanksxmas + received_award +
               maturity_rating + genre_primary)


cat("Summary for models 1 to 3:")

stargazer(model_1,
          model_2,
          model_3,
          type = 'text',
          se = list(get_robust_se(model_1),
                    get_robust_se(model_2),
                    get_robust_se(model_3)
                    )
          )
```
```{r f-test for model_1, model_2 and model_3}
anova(model_1, model_2, test = 'F')
# The p-value is less than 0.05 thus we can reject the null hypothesis, the additional parameter that we have estimated in `model_2` makes this second model more fully represent the true population.
anova(model_2, model_3, test = 'F')
# Between model_2 and model_3 the additional covariate genre_primary in model_3 
# have explanatory power and improves the fit of the model. The null hypothesis is 
# that model_2 model_3 have equal residual sum of squares. A F test was
# conducted. Assumptions of F test: 1) the population must be normally
# distributed and 2) the samples must be independent events. If the
# probability (p-value) of observing F-value that is at least as large
# as the F-value that the study got (4.292) is lower than 0.05, then we
# can reject the null hypothesis. We can conclude by rejecting our null
# hypothesis since the p-value is less than 0.05 in this case. Model 3
# with additional covariates have explanatory power (is able to explain
# the variance in the dependent variable better than model 1 and 2) and are
# improving the model performance.
```
```{r print regression tables with robust standard errors}
coeftest(model_1, vcovHC, type = "HC1")
coeftest(model_3, vcovHC, type = "HC1")
```